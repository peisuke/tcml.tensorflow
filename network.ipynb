{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('data.npy')\n",
    "data = np.reshape(data,[-1,20,28,28])\n",
    "train_data = data[:1200,:,:,:]\n",
    "test_data = data[1200:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(nb_batch, nb_episode, nb_class, data):\n",
    "    dshape = data.shape[2:]\n",
    "    batch_x = np.zeros((nb_batch, nb_episode) + dshape + (1,))\n",
    "    batch_test = np.zeros((nb_batch, nb_episode, 2))\n",
    "    batch_y = np.zeros((nb_batch, nb_episode))\n",
    "    batch_mask = np.ones((nb_batch, nb_episode))\n",
    "    nb_class_total = len(data)\n",
    "    \n",
    "    for i in range(nb_batch):\n",
    "        # classes for learning\n",
    "        classes = np.random.choice(nb_class_total, nb_class, False)\n",
    "        \n",
    "        # index to class\n",
    "        # class_idx is classes[pinds[i]]\n",
    "        pidx = np.random.permutation(nb_class)\n",
    "        \n",
    "        # sample data\n",
    "        sample = np.random.randint(0, nb_class, nb_episode)\n",
    "        batch_y[i] = sample\n",
    "        \n",
    "        _, first = np.unique(sample, return_index=True)\n",
    "        mask = np.ones(nb_episode, np.bool)\n",
    "        mask[first] = False\n",
    "        batch_mask[i] = mask\n",
    "        \n",
    "        for j in range(nb_class):\n",
    "            idx = (sample == j)\n",
    "            eidx = np.random.choice(data.shape[1], np.sum(sample == j), False)\n",
    "            imgs = data[classes[pidx[j]], eidx]\n",
    "            \n",
    "            batch_x[i, idx, :, :, 0] = np.rot90(imgs, np.random.randint(4), axes=(1,2))\n",
    "            batch_test[i, idx, 0] = classes[pidx[j]]\n",
    "            batch_test[i, idx, 1] = eidx\n",
    "            \n",
    "    return batch_x, batch_y, batch_mask, batch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_batch = 4\n",
    "nb_episode = 32\n",
    "nb_class = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_x, batch_y, batch_m, _ = get_minibatch(nb_batch, nb_episode, nb_class, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_input(batch_y, nb_class):    \n",
    "    batch_p = (np.arange(nb_class) == batch_y[:,:-1,None]).astype(int)\n",
    "    dummy = np.zeros((nb_batch, 1, nb_class), dtype=np.float32)\n",
    "    return np.concatenate((dummy, batch_p), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_p = make_input(batch_y, nb_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 32, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input image\n",
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 32, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previous Label\n",
    "batch_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  4.,  2.,  1.,  2.,  0.,  3.,  1.,  0.,  2.,  0.,  0.,\n",
       "         0.,  3.,  1.,  0.,  4.,  1.,  2.,  1.,  0.,  2.,  4.,  0.,  3.,\n",
       "         1.,  0.,  4.,  0.,  2.,  1.],\n",
       "       [ 1.,  1.,  3.,  4.,  2.,  2.,  4.,  2.,  3.,  0.,  0.,  1.,  3.,\n",
       "         3.,  0.,  2.,  2.,  3.,  2.,  0.,  3.,  3.,  0.,  2.,  4.,  2.,\n",
       "         0.,  1.,  2.,  1.,  2.,  0.],\n",
       "       [ 2.,  1.,  2.,  0.,  2.,  1.,  4.,  0.,  4.,  0.,  1.,  2.,  4.,\n",
       "         3.,  2.,  3.,  1.,  2.,  3.,  3.,  3.,  1.,  2.,  4.,  1.,  3.,\n",
       "         3.,  1.,  3.,  2.,  1.,  2.],\n",
       "       [ 3.,  0.,  2.,  0.,  1.,  1.,  4.,  4.,  3.,  3.,  4.,  4.,  1.,\n",
       "         3.,  1.,  0.,  1.,  2.,  1.,  4.,  4.,  0.,  2.,  0.,  0.,  1.,\n",
       "         3.,  1.,  3.,  4.,  2.,  2.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(batch_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embd_net(inp, scope, reuse=False, stop_grad=False):\n",
    "    nb_episode = int(inp.shape[1])\n",
    "    \n",
    "    with tf.variable_scope(scope) as varscope:\n",
    "        if reuse: \n",
    "            varscope.reuse_variables()\n",
    "\n",
    "        _inp = tf.reshape(inp, [-1, 28, 28, 1])\n",
    "        cur_input = _inp\n",
    "        cur_filters = 1\n",
    "        \n",
    "        for i in range(4):\n",
    "            with tf.variable_scope('conv'+str(i)):\n",
    "                W = tf.get_variable('W', [3, 3, cur_filters, 64])\n",
    "                beta = tf.get_variable('beta', [64], initializer=tf.constant_initializer(0.0))\n",
    "                gamma = tf.get_variable('gamma', [64], initializer=tf.constant_initializer(1.0))\n",
    "\n",
    "                cur_filters = 64\n",
    "                pre_norm = tf.nn.conv2d(cur_input, W, strides=[1,1,1,1], padding='SAME')\n",
    "                mean, variance = tf.nn.moments(pre_norm, [0, 1, 2])\n",
    "                post_norm = tf.nn.batch_normalization(pre_norm, mean, variance, beta, gamma, variance_epsilon = 1e-10)\n",
    "                conv = tf.nn.relu(post_norm)\n",
    "                cur_input = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding = 'VALID')\n",
    "\n",
    "        if stop_grad:\n",
    "            squeezed = tf.squeeze(cur_input, [1,2])\n",
    "            output = tf.stop_gradient(tf.reshape(squeezed, [-1, nb_episode, 64]))\n",
    "        else:\n",
    "            squeezed = tf.squeeze(cur_input, [1,2])\n",
    "            output = tf.reshape(squeezed, [-1, nb_episode, 64])\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calual_conv_with_activation(inp, nb_input, nb_output, dilation_rate):\n",
    "        Wf = tf.get_variable('W_filter', [2, nb_input, nb_output])\n",
    "        bf = tf.get_variable('b_filter', [nb_output])    \n",
    "        Wg = tf.get_variable('W_gate', [2, nb_input, nb_output])\n",
    "        bg = tf.get_variable('b_gate', [nb_output])            \n",
    "        \n",
    "        x = tf.pad(inp, [[0, 0], [dilation_rate, 0], [0, 0]])\n",
    "        \n",
    "        xf = tf.nn.convolution(x, Wf, strides=[1,], dilation_rate=[dilation_rate,], padding='VALID')\n",
    "        xf = tf.nn.bias_add(xf, bf)\n",
    "        \n",
    "        xg = tf.nn.convolution(x, Wg, strides=[1,], dilation_rate=[dilation_rate,], padding='VALID')\n",
    "        xg = tf.nn.bias_add(xg, bg)\n",
    "        \n",
    "        out = tf.tanh(xf) * tf.sigmoid(xg)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def res_block(inp, nb_dim, dilation_rate, scope):\n",
    "    with tf.variable_scope(scope):\n",
    "        x = calual_conv_with_activation(inp, nb_dim, nb_dim, dilation_rate)\n",
    "        x = x + inp\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_block(inp, nb_dim, dilation_rate, scope):\n",
    "    with tf.variable_scope(scope):\n",
    "        x = calual_conv_with_activation(inp, nb_dim, 128, dilation_rate)\n",
    "        x = res_block(x, 128, dilation_rate, 'res_01')\n",
    "        x = res_block(x, 128, dilation_rate, 'res_02')\n",
    "        \n",
    "        x = tf.concat((inp, x), axis=2)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tcml(inp, label, scope, reuse=False, stop_grad=False):\n",
    "    with tf.variable_scope(scope):\n",
    "        with tf.variable_scope('preprocess'):\n",
    "            x = tf.concat((inp, label), axis=2)\n",
    "\n",
    "        nb_channel = int(x.shape[2])\n",
    "        x = dense_block(x, nb_channel+0*128, 1, 'dense_01')\n",
    "        x = dense_block(x, nb_channel+1*128, 2, 'dense_02')\n",
    "        x = dense_block(x, nb_channel+2*128, 4, 'dense_03')\n",
    "        x = dense_block(x, nb_channel+3*128, 8, 'dense_04')\n",
    "        x = dense_block(x, nb_channel+4*128, 16, 'dense_05')\n",
    "        x = dense_block(x, nb_channel+5*128, 1, 'dense_06',)\n",
    "        x = dense_block(x, nb_channel+6*128, 2, 'dense_07',)\n",
    "        x = dense_block(x, nb_channel+7*128, 4, 'dense_08')\n",
    "        x = dense_block(x, nb_channel+8*128, 8, 'dense_09')\n",
    "        x = dense_block(x, nb_channel+9*128, 16, 'dense_10')\n",
    "        \n",
    "        with tf.variable_scope('postprocess'):\n",
    "            W1 = tf.get_variable('W1', [1, nb_channel+10*128, 512])\n",
    "            b1 = tf.get_variable('b1', [512])\n",
    "            W2 = tf.get_variable('W2', [1, 512, 5])\n",
    "            b2 = tf.get_variable('b2', [5])\n",
    "\n",
    "            x = tf.nn.conv1d(x, W1, stride=1, padding='SAME')\n",
    "            x = tf.nn.bias_add(x, b1)\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x = tf.nn.conv1d(x, W2, stride=1, padding='SAME')            \n",
    "            x = tf.nn.bias_add(x, b2)\n",
    "\n",
    "        with tf.variable_scope('output'):\n",
    "            output = tf.nn.softmax(x)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build(img, prev_label):\n",
    "    feature = embd_net(img, 'embd')\n",
    "    tcml = build_tcml(feature, prev_label, 'TCML')\n",
    "    \n",
    "    return tcml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = tf.placeholder(tf.float32, shape=[None, nb_episode, 28, 28, 1])\n",
    "prev_label = tf.placeholder(tf.float32, shape=[None, nb_episode, 5])\n",
    "\n",
    "net = build(img, prev_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter('./log', graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    img: batch_x,\n",
    "    prev_label: batch_p\n",
    "}\n",
    "ret = sess.run(net, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 32, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
